{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M_TD-IDF_PolEmo2.0_logisticregresion",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1frdlj67sRQhXuj_ND3DEWJBSNfqbY5U_",
      "authorship_tag": "ABX9TyPRUD2Ds/lVXwv/vLfqVlp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogus1aw/text-classification-benchmark/blob/main/M_TD_IDF_PolEmo2_0_logisticregresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3PAWlQbvxud"
      },
      "source": [
        "# TF-IDF benchmark for PolEmo 2.0 dataset https://clarin-pl.eu/dspace/handle/11321/710\r\n",
        "\r\n",
        "gdrive mounted manually form GUI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds8qiFIctn1R"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn import decomposition, ensemble\r\n",
        "\r\n",
        "import pandas, xgboost, numpy, textblob, string\r\n",
        "from keras.preprocessing import text, sequence\r\n",
        "from keras import layers, models, optimizers\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import datetime\r\n",
        "import time\r\n",
        "\r\n",
        "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat().replace(':', '-')\r\n",
        "metrice_path = '/content/drive/MyDrive/metrics/tf-idf_PolEmo2.0_logisticregression_raw' + timestamp + '.txt'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Advfk4w3Y8"
      },
      "source": [
        "# 1. Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FSc9zBweR1"
      },
      "source": [
        "def load_corpora_to_dataframe(corpora):\r\n",
        "  data = open(corpora).read()\r\n",
        "  labels, texts = [], []\r\n",
        "  for i, line in enumerate(data.split(\"\\n\")):\r\n",
        "      content = line.split()\r\n",
        "      if len(content) > 0: \r\n",
        "        labels.append(content[-1])\r\n",
        "        texts.append(\" \".join(content[:-1]))\r\n",
        "\r\n",
        "  # create a dataframe using texts and lables\r\n",
        "  trainDF = pandas.DataFrame()\r\n",
        "  trainDF['text'] = texts\r\n",
        "  trainDF['label'] = labels\r\n",
        "  return trainDF"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8KlahQByMYt"
      },
      "source": [
        "def calculate_feature_vectors_tfifd(max_features, train_dataframe, valid_x, valid_y):\r\n",
        "  # word level tf-idf\r\n",
        "  tfidf_vect = TfidfVectorizer(analyzer='word', max_features=max_features)\r\n",
        "  tfidf_vect.fit(train_dataframe['text']) \r\n",
        "  xtrain_tfidf =  tfidf_vect.transform(train_dataframe['text'])\r\n",
        "  xvalid_tfidf =  tfidf_vect.transform(valid_x)\r\n",
        "  # ngram level tf-idf \r\n",
        "  tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(1,2 ), max_features=max_features)\r\n",
        "  tfidf_vect_ngram.fit(train_dataframe['text'])\r\n",
        "  xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_dataframe['text'])\r\n",
        "  xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)\r\n",
        "  return xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKEpEjm6yuTd"
      },
      "source": [
        "def clasification_benchmark(txt_description, classifier, train_y, feature_vector_train, feature_vector_valid):\r\n",
        "  classifier.fit(feature_vector_train, train_y)\r\n",
        "  predictions = classifier.predict(feature_vector_valid)\r\n",
        "  accuracy = metrics.accuracy_score(valid_y, predictions)\r\n",
        "  print(txt_description, ' ', accuracy)\r\n",
        "  return accuracy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7u_0dX3zgG"
      },
      "source": [
        "def calculate_classifiers_accuracy(max_feature, train_dataframe, train_y, valid_x, valid_y):\r\n",
        "\r\n",
        "  xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram = calculate_feature_vectors_tfifd(max_feature, train_dataframe, valid_x, valid_y)\r\n",
        "  acc_arr = []\r\n",
        "  acc_arr.append(clasification_benchmark('LR, word,       ', linear_model.LogisticRegression(), train_y, xtrain_tfidf, xvalid_tfidf)) \r\n",
        "  acc_arr.append(clasification_benchmark('LR, (1-2)gram   ', linear_model.LogisticRegression(), train_y, xtrain_tfidf_ngram, xvalid_tfidf_ngram))\r\n",
        "  return acc_arr"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0lduGuFZO9g"
      },
      "source": [
        "# 2. Constants and paths defintion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4jxpoEFWUPg"
      },
      "source": [
        "fig_path = '/content/drive/MyDrive/figures/'\r\n",
        "max_feature = 20000\r\n",
        "no_samples_per_class = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 400, 800, 1200]\r\n",
        " "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od8fvaJtZg3R"
      },
      "source": [
        "# 3. Benchmarks\r\n",
        "## 3.1 Raw corpora benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46L_V3CK5oR"
      },
      "source": [
        "def benchamrk(CORPORA_TRAIN, CORPORA_TEST) :\r\n",
        "  train = load_corpora_to_dataframe(CORPORA_TRAIN)\r\n",
        "  test = load_corpora_to_dataframe(CORPORA_TEST)\r\n",
        "\r\n",
        "  # test dataset will be always the same for ale tests \r\n",
        "  # train, test = model_selection.train_test_split(trainDF, test_size=0.2, random_state=42)\r\n",
        "  valid_x = test['text']\r\n",
        "  valid_y = test['label']\r\n",
        "\r\n",
        "  encoder = preprocessing.LabelEncoder()\r\n",
        "  valid_y = encoder.fit_transform(valid_y)\r\n",
        "\r\n",
        "  accurracy_matrix = []\r\n",
        "\r\n",
        "  for n_sample in no_samples_per_class:\r\n",
        "    print(n_sample)\r\n",
        "    dataset_fraction = train.groupby(['label']).sample(n=n_sample, replace=True)\r\n",
        "\r\n",
        "    train_y = encoder.fit_transform(dataset_fraction['label'])\r\n",
        "    accurracy_per_run = calculate_classifiers_accuracy(max_feature, dataset_fraction, train_y, valid_x, valid_y)\r\n",
        "    accurracy_matrix.append([n_sample] + accurracy_per_run)\r\n",
        "    with open(metrice_path, 'a') as f:\r\n",
        "        f.write(str([n_sample] + accurracy_per_run))\r\n",
        "\r\n",
        "  df = pandas.DataFrame(accurracy_matrix)\r\n",
        "  return df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "RBwIT70gGqjC",
        "outputId": "47e29b99-c034-48a7-d4d5-c7c92dc0eb0d"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/all.text.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/all.text.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8286179e45d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCORPORA_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/master_datasets/dataset_conll/all.text.train.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCORPORA_TEST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/master_datasets/dataset_conll/all.text.test.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchamrk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCORPORA_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCORPORA_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5ed088d884c8>\u001b[0m in \u001b[0;36mbenchamrk\u001b[0;34m(CORPORA_TRAIN, CORPORA_TEST)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_fraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0maccurracy_per_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_classifiers_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0maccurracy_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maccurracy_per_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrice_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-29b76f9522b7>\u001b[0m in \u001b[0;36mcalculate_classifiers_accuracy\u001b[0;34m(max_feature, train_dataframe, valid_x, valid_y)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mxtrain_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain_tfidf_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid_tfidf_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_feature_vectors_tfifd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0macc_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0macc_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasification_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR, word,       '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0macc_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasification_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR, (1-2)gram   '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain_tfidf_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid_tfidf_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0macc_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e118489fc556>\u001b[0m in \u001b[0;36mclasification_benchmark\u001b[0;34m(txt_description, classifier, feature_vector_train, feature_vector_valid)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclasification_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPCk36eHFGN"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/all.sentence.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/all.sentence.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVSv3ZBfHFQM"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.text.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.text.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMH6sY3xHFY8"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.sentence.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.sentence.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wGlRhFH2Is"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/Nhotels.text.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.text.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvvX29AfH2Sk"
      },
      "source": [
        "CORPORA_TRAIN = '/content/drive/MyDrive/master_datasets/dataset_conll/Nhotels.sentence.train.txt'\r\n",
        "CORPORA_TEST = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.sentence.test.txt'\r\n",
        "df = benchamrk(CORPORA_TRAIN, CORPORA_TEST)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}