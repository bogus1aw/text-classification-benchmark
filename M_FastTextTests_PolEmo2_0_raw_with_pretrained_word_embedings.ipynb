{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "M_FastTextTests_PolEmo2.0 raw_with_pretrained_word_embedings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogus1aw/text-classification-benchmark/blob/main/M_FastTextTests_PolEmo2_0_raw_with_pretrained_word_embedings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzZtBMi31V8"
      },
      "source": [
        "FastText benchmark for PolEmo 2.0 dataset https://clarin-pl.eu/dspace/handle/11321/710\r\n",
        "\r\n",
        "how to use pretrianed vectors https://stackoverflow.com/questions/64706753/how-to-use-pre-trained-word-vectors-in-fasttext/64711974#64711974"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMjJBF8EUzx4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8xW4DmI5UaM",
        "outputId": "bbdac934-3c4e-445c-cad8-34159c799674"
      },
      "source": [
        "# install fastText\r\n",
        "!git clone https://github.com/facebookresearch/fastText.git\r\n",
        "%cd fastText\r\n",
        "!sudo pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3854/3854), 8.22 MiB | 31.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2417/2417), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (53.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3082260 sha256=254e672cf5dafe78acc77a10d4f90327998692d1992b2e17c391067c0c8728f3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gibzt2ce/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG5L1DIu4DM8"
      },
      "source": [
        "import fasttext as ft\r\n",
        "import fasttext.util\r\n",
        "import pandas as pd\r\n",
        "from sklearn import model_selection\r\n",
        "import csv\r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkpWvQAxDFbf"
      },
      "source": [
        "# fasttext.util.download_model('pl', if_exists='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MZMWjIt5gTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028e6646-a897-441f-851a-10860f44f1f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KZn3NHEQHpU"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pl.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcW0iBdvQYv6"
      },
      "source": [
        "# !pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8HHghoQtob"
      },
      "source": [
        "# !gzip -l /content/drive/MyDrive/models/cc.pl.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzrZbU95Y8VB"
      },
      "source": [
        "# %ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9HX3RbHDUl"
      },
      "source": [
        "# ft = fasttext.load_model('/content/drive/MyDrive/models/cc.pl.300.bin')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8D3a8QrZ2FP"
      },
      "source": [
        "# with open('/content/drive/MyDrive/models/cc.pl.300.vec','r') as file_out:\r\n",
        "#   print(file_out.readline())\r\n",
        "#   print(file_out.readline())\r\n",
        "#   print(file_out.readline())\r\n",
        "#   print(file_out.readline())\r\n",
        "#   print(file_out.readline())\r\n",
        "#   print(file_out.readline())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnZW5kXjI8zF"
      },
      "source": [
        "# type(ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHprSeQAKMdk"
      },
      "source": [
        "# ft.get_dimension()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNj-MKUBOQVT"
      },
      "source": [
        "# fasttext.util.reduce_model(ft, 100) failing host"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9k4IU6eSuyB"
      },
      "source": [
        "# ft.get_dimension()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUDgpqIkTip6"
      },
      "source": [
        "# from fastText import load_model\r\n",
        "\r\n",
        "# # original BIN model loading\r\n",
        "# f = load_model(YOUR-BIN-MODEL-PATH)\r\n",
        "#     lines=[]\r\n",
        "\r\n",
        "# get all words from model\r\n",
        "# words = ft.get_words()\r\n",
        "\r\n",
        "# VEC_FILE_PATH = 'cc.pl.300.created.vec'\r\n",
        "\r\n",
        "# with open(VEC_FILE_PATH,'w') as file_out:\r\n",
        "    \r\n",
        "#     # the first line must contain number of total words and vector dimension\r\n",
        "#     file_out.write(str(len(words)) + \" \" + str(ft.get_dimension()) + \"\\n\")\r\n",
        "\r\n",
        "#     # line by line, you append vectors to VEC file\r\n",
        "#     for w in words:\r\n",
        "#         v = ft.get_word_vector(w)\r\n",
        "#         vstr = \"\"\r\n",
        "#         for vi in v:\r\n",
        "#             vstr += \" \" + str(vi)\r\n",
        "#         try:\r\n",
        "#             file_out.write(w + vstr+'\\n')\r\n",
        "#         except:\r\n",
        "#             pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxrAqPS5KbP7"
      },
      "source": [
        "# TRAIN_FASTTEXT_FILE_PATH = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.text.train.txt'\r\n",
        "# model = fasttext.train_supervised(input=TRAIN_FASTTEXT_FILE_PATH, dim=300, lr=1.0, epoch=25, pretrainedVectors='/content/drive/MyDrive/models/cc.pl.300.vec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoE4mnapXQr3"
      },
      "source": [
        "# TEST_FASTTEXT_FILE_PATH = '/content/drive/MyDrive/master_datasets/dataset_conll/hotels.text.test.txt'\r\n",
        "# result = model.test(TEST_FASTTEXT_FILE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paU6nYS2beQX"
      },
      "source": [
        "# result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWAVBgSvZMJu"
      },
      "source": [
        "#create work dir\r\n",
        "WORK_PATH = '/content/data/'\r\n",
        "%mkdir -p '/content/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O2ia0Dk-njO"
      },
      "source": [
        "# PATH DEFINITION FOR CORPORA\r\n",
        "TEST_FASTTEXT_FILE_PATH = WORK_PATH + 'TEST_FASTEXT_WORK.csv'\r\n",
        "TRAIN_FASTTEXT_FILE_PATH = WORK_PATH + 'TRAIN_FASTEXT_WORK.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsiKx1tP-Y-v"
      },
      "source": [
        "def load_corpora_to_dataframe(corpora):\r\n",
        "  data = open(corpora).read()\r\n",
        "  labels, texts = [], []\r\n",
        "  for i, line in enumerate(data.split(\"\\n\")):\r\n",
        "      content = line.split()\r\n",
        "      if len(content) > 0: \r\n",
        "        labels.append(content[-1])\r\n",
        "        texts.append(\" \".join(content[:-1]))\r\n",
        "\r\n",
        "  # create a dataframe using texts and lables\r\n",
        "  trainDF = pd.DataFrame()\r\n",
        "  trainDF['text'] = texts\r\n",
        "  trainDF['label'] = labels\r\n",
        "  return trainDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln-wr0oJWCV_"
      },
      "source": [
        "def process_benchmark(domain, train, test, wordNgrams):\n",
        "  # save text file which will be used for all tests\n",
        "  test.to_csv(TEST_FASTTEXT_FILE_PATH, header=False, index=False, encoding='utf-8', sep='\\t', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "  full = []\n",
        "  for repeat in range(repetitions):\n",
        "      iteration = []\n",
        "      for n_samples in no_samples_per_class:\n",
        "          train_work = train.groupby(['label']).sample(n=n_samples, replace=True)\n",
        "          train_work = train_work.sample(frac=1)\n",
        "          train_work.to_csv(TRAIN_FASTTEXT_FILE_PATH, header=False, index=False, encoding='utf-8', sep='\\t', quoting=csv.QUOTE_NONE)\n",
        "          # model = ft.train_supervised(input=TRAIN_FASTTEXT_FILE_PATH, lr=1.0, epoch=25, wordNgrams=wordNgrams)\n",
        "          model = ft.train_supervised(input=TRAIN_FASTTEXT_FILE_PATH, dim=300, lr=1.0, epoch=25, pretrainedVectors='/content/drive/MyDrive/models/cc.pl.300.vec', wordNgrams=wordNgrams)\n",
        "          result = model.test(TEST_FASTTEXT_FILE_PATH)\n",
        "          print('domain: ', domain, \" repeat: \", repeat,\" sample: \", n_samples,' wordNgrams: ', wordNgrams, ' results: ', result)\n",
        "          iteration.append(result[1])\n",
        "      print(iteration)\n",
        "      full.append(iteration)\n",
        "  \n",
        "  return full\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e49jSUyQ-bQt"
      },
      "source": [
        "no_samples_per_class = [1, 3, 5, 8, 10, 20, 30, 60, 100, 200] ###### FINALL SAMPLES LIST  \n",
        "repetitions = 2\n",
        "# grams = [1, 2]\n",
        "grams = [1]\n",
        "\n",
        "\n",
        "# metrice_path = '/content/drive/MyDrive/metrics/tf-idf_PolEmo2.0_logisticregression_raw' + timestamp + '.txt'\n",
        "fig_path = '/content/drive/MyDrive/figures/'\n",
        "dataset_path = '/content/drive/MyDrive/master_datasets/dataset_conll/'\n",
        "\n",
        "domains = [\n",
        "          #  ('all', 'MDT-A'),\n",
        "          #  ('hotels', 'SDT-H'),\n",
        "           ('medicine', 'SDT-M'),\n",
        "           ('products', 'SDT-P'),\n",
        "           ('reviews', 'SDT-R')\n",
        "          ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS40CX16eIDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a47b56-e18b-4730-dd6a-a9bee4886abc"
      },
      "source": [
        "df = pd.DataFrame()\r\n",
        "   \r\n",
        "for domian, ix_name in domains:\r\n",
        "  for ngram in grams :\r\n",
        "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\r\n",
        "    print('%%%%%%%%  ', domian,  ' ', ngram)\r\n",
        "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\r\n",
        "    \r\n",
        "    CORPORA_TRAIN = dataset_path + domian + '.text.train.txt'\r\n",
        "    CORPORA_TEST = dataset_path + domian + '.text.test.txt'\r\n",
        "    train = load_corpora_to_dataframe(CORPORA_TRAIN)\r\n",
        "    test = load_corpora_to_dataframe(CORPORA_TEST)\r\n",
        "\r\n",
        "    results = process_benchmark(ix_name, train, test, ngram)\r\n",
        "\r\n",
        "    df = df.append(pd.DataFrame(pd.DataFrame(results, columns=no_samples_per_class).mean(), columns=[ix_name + '_R_' + str(ngram)]).T)\r\n",
        "\r\n",
        "df\r\n",
        "### RAW"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "%%%%%%%%   all   1\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "domain:  MDT-A  repeat:  0  sample:  1  wordNgrams:  1  results:  (820, 0.42317073170731706, 0.42317073170731706)\n",
            "domain:  MDT-A  repeat:  0  sample:  3  wordNgrams:  1  results:  (820, 0.42317073170731706, 0.42317073170731706)\n",
            "domain:  MDT-A  repeat:  0  sample:  5  wordNgrams:  1  results:  (820, 0.4036585365853659, 0.4036585365853659)\n",
            "domain:  MDT-A  repeat:  0  sample:  8  wordNgrams:  1  results:  (820, 0.5414634146341464, 0.5414634146341464)\n",
            "domain:  MDT-A  repeat:  0  sample:  10  wordNgrams:  1  results:  (820, 0.5121951219512195, 0.5121951219512195)\n",
            "domain:  MDT-A  repeat:  0  sample:  20  wordNgrams:  1  results:  (820, 0.5719512195121951, 0.5719512195121951)\n",
            "domain:  MDT-A  repeat:  0  sample:  30  wordNgrams:  1  results:  (820, 0.5073170731707317, 0.5073170731707317)\n",
            "domain:  MDT-A  repeat:  0  sample:  60  wordNgrams:  1  results:  (820, 0.6158536585365854, 0.6158536585365854)\n",
            "domain:  MDT-A  repeat:  0  sample:  100  wordNgrams:  1  results:  (820, 0.6841463414634147, 0.6841463414634147)\n",
            "domain:  MDT-A  repeat:  0  sample:  200  wordNgrams:  1  results:  (820, 0.6890243902439024, 0.6890243902439024)\n",
            "[0.42317073170731706, 0.42317073170731706, 0.4036585365853659, 0.5414634146341464, 0.5121951219512195, 0.5719512195121951, 0.5073170731707317, 0.6158536585365854, 0.6841463414634147, 0.6890243902439024]\n",
            "domain:  MDT-A  repeat:  1  sample:  1  wordNgrams:  1  results:  (820, 0.2817073170731707, 0.2817073170731707)\n",
            "domain:  MDT-A  repeat:  1  sample:  3  wordNgrams:  1  results:  (820, 0.47804878048780486, 0.47804878048780486)\n",
            "domain:  MDT-A  repeat:  1  sample:  5  wordNgrams:  1  results:  (820, 0.39634146341463417, 0.39634146341463417)\n",
            "domain:  MDT-A  repeat:  1  sample:  8  wordNgrams:  1  results:  (820, 0.49634146341463414, 0.49634146341463414)\n",
            "domain:  MDT-A  repeat:  1  sample:  10  wordNgrams:  1  results:  (820, 0.5158536585365854, 0.5158536585365854)\n",
            "domain:  MDT-A  repeat:  1  sample:  20  wordNgrams:  1  results:  (820, 0.5682926829268292, 0.5682926829268292)\n",
            "domain:  MDT-A  repeat:  1  sample:  30  wordNgrams:  1  results:  (820, 0.5646341463414634, 0.5646341463414634)\n",
            "domain:  MDT-A  repeat:  1  sample:  60  wordNgrams:  1  results:  (820, 0.5914634146341463, 0.5914634146341463)\n",
            "domain:  MDT-A  repeat:  1  sample:  100  wordNgrams:  1  results:  (820, 0.6609756097560976, 0.6609756097560976)\n",
            "domain:  MDT-A  repeat:  1  sample:  200  wordNgrams:  1  results:  (820, 0.6670731707317074, 0.6670731707317074)\n",
            "[0.2817073170731707, 0.47804878048780486, 0.39634146341463417, 0.49634146341463414, 0.5158536585365854, 0.5682926829268292, 0.5646341463414634, 0.5914634146341463, 0.6609756097560976, 0.6670731707317074]\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "%%%%%%%%   hotels   1\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "domain:  SDT-H  repeat:  0  sample:  1  wordNgrams:  1  results:  (395, 0.43037974683544306, 0.43037974683544306)\n",
            "domain:  SDT-H  repeat:  0  sample:  3  wordNgrams:  1  results:  (395, 0.3518987341772152, 0.3518987341772152)\n",
            "domain:  SDT-H  repeat:  0  sample:  5  wordNgrams:  1  results:  (395, 0.4810126582278481, 0.4810126582278481)\n",
            "domain:  SDT-H  repeat:  0  sample:  8  wordNgrams:  1  results:  (395, 0.549367088607595, 0.549367088607595)\n",
            "domain:  SDT-H  repeat:  0  sample:  10  wordNgrams:  1  results:  (395, 0.4759493670886076, 0.4759493670886076)\n",
            "domain:  SDT-H  repeat:  0  sample:  20  wordNgrams:  1  results:  (395, 0.6050632911392405, 0.6050632911392405)\n",
            "domain:  SDT-H  repeat:  0  sample:  30  wordNgrams:  1  results:  (395, 0.640506329113924, 0.640506329113924)\n",
            "domain:  SDT-H  repeat:  0  sample:  60  wordNgrams:  1  results:  (395, 0.640506329113924, 0.640506329113924)\n",
            "domain:  SDT-H  repeat:  0  sample:  100  wordNgrams:  1  results:  (395, 0.6506329113924051, 0.6506329113924051)\n",
            "domain:  SDT-H  repeat:  0  sample:  200  wordNgrams:  1  results:  (395, 0.7316455696202532, 0.7316455696202532)\n",
            "[0.43037974683544306, 0.3518987341772152, 0.4810126582278481, 0.549367088607595, 0.4759493670886076, 0.6050632911392405, 0.640506329113924, 0.640506329113924, 0.6506329113924051, 0.7316455696202532]\n",
            "domain:  SDT-H  repeat:  1  sample:  1  wordNgrams:  1  results:  (395, 0.3189873417721519, 0.3189873417721519)\n",
            "domain:  SDT-H  repeat:  1  sample:  3  wordNgrams:  1  results:  (395, 0.3721518987341772, 0.3721518987341772)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}